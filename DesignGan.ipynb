{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DesignGan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-VtcEnn--jT"
      },
      "outputs": [],
      "source": [
        "### import necessary library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from dataloader import data_loader\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import model\n",
        "import util\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "2CkxMJm7_Ev3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function\n",
        "def mse_loss(score,target=1):  \n",
        "    dtype = type(score)  \n",
        "    if target == 1:\n",
        "        label = torch.ones(score.size(),requires_grad=False).to(device)\n",
        "    elif target == 0:\n",
        "        label = torch.zeros(score.size(),requires_grad=False).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    loss = criterion(score, label)\n",
        "    return loss\n",
        "\n",
        "def L1_loss(pred, target):\n",
        "    return torch.mean(torch.abs(pred - target))\n",
        "\n",
        "class Vgg19(nn.Module):\n",
        "    def __init__(self, requires_grad=False):\n",
        "        super(Vgg19, self).__init__()\n",
        "        vgg_pretrained_features = models.vgg19(pretrained=True).features\n",
        "        self.slice1 = torch.nn.Sequential()\n",
        "        self.slice2 = torch.nn.Sequential()\n",
        "        self.slice3 = torch.nn.Sequential()\n",
        "        self.slice4 = torch.nn.Sequential()\n",
        "        self.slice5 = torch.nn.Sequential()\n",
        "        for x in range(2):\n",
        "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(2, 7):\n",
        "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(7, 12):\n",
        "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(12, 21):\n",
        "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(21, 30):\n",
        "            self.slice5.add_module(str(x), vgg_pretrained_features[x])\n",
        "        if not requires_grad:\n",
        "            for param in self.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, X):\n",
        "        h_relu1 = self.slice1(X)\n",
        "        h_relu2 = self.slice2(h_relu1)\n",
        "        h_relu3 = self.slice3(h_relu2)\n",
        "        h_relu4 = self.slice4(h_relu3)\n",
        "        h_relu5 = self.slice5(h_relu4)\n",
        "        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]\n",
        "        return out\n",
        "\n",
        "class VGGLoss(nn.Module):\n",
        "    def __init__(self, layids = None):\n",
        "        super(VGGLoss, self).__init__()\n",
        "        self.vgg = Vgg19()\n",
        "        self.vgg.to(device)\n",
        "        self.criterion = nn.L1Loss()\n",
        "        self.weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]\n",
        "        self.layids = layids\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
        "        loss = 0\n",
        "        if self.layids is None:\n",
        "            self.layids = list(range(len(x_vgg)))\n",
        "        for i in self.layids:\n",
        "            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())\n",
        "        return loss"
      ],
      "metadata": {
        "id": "_-eoeiue_Gn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define DesignGAN class\n",
        "class DesignGAN():\n",
        "    def __init__(self,batch_size, num_epoch,load_weight=False):\n",
        "        self.weight_dir = './output/weights'\n",
        "        self.result_dir = './output/images'\n",
        "        self.gen_image_path = './output/gen_images'\n",
        "        self.img_size = 256\n",
        "        self.batch_size = batch_size\n",
        "        self.start_epoch = 0\n",
        "        self.num_epoch = num_epoch\n",
        "        self.save_interval = 50\n",
        "        self.Rms_lr=2e-4\n",
        "        self.weight_decay = 1e-5   # first = 6e-8\n",
        "        self.Adam_lr=0.0002\n",
        "        self.beta_1=0.5\n",
        "        self.beta_2=0.999\n",
        "        #self.lambda_kl=0.01\n",
        "        self.lambda_img=3   #100\n",
        "        self.criterionVGG = VGGLoss()\n",
        "        self.z_dim=512\n",
        "        self.load_weight = load_weight\n",
        "        self.test_size = 1\n",
        "        self.test_img_num = 1\n",
        "        # Data type(Can use GPU or CPU)\n",
        "        self.dtype = torch.cuda.FloatTensor\n",
        "        if torch.cuda.is_available() != True:\n",
        "            self.dtype = torch.FloatTensor\n",
        "        # load data for training\n",
        "        self.dloader = data_loader(batch_size=self.batch_size,shuffle=True)\n",
        "        # load data for test\n",
        "        self.t_dloader = data_loader(batch_size=self.test_size, shuffle=True)        \n",
        "        # load model\n",
        "        #self.M = model.Mapping(init_weights=True).type(self.dtype)\n",
        "        #self.E = model.Extractor(z_dim=self.z_dim).to(device)\n",
        "        self.G = model.Generator(init_weights=True).to(device)\n",
        "        self.D = model.Discriminator(init_weights=True).to(device)\n",
        "        # define optimizer\n",
        "        self.optim_D = optim.Adam(self.D.parameters(),lr=self.Adam_lr,betas=(self.beta_1, self.beta_2))\n",
        "        self.optim_G = optim.Adam(self.G.parameters(),lr=self.Adam_lr,betas=(self.beta_1, self.beta_2))\n",
        "        #self.optim_E = optim.RMSprop(self.E.parameters(),lr=self.Rms_lr,weight_decay=self.weight_decay)\n",
        "        #self.optim_E = optim.Adam(self.E.parameters(),lr=self.Adam_lr,betas=(self.beta_1, self.beta_2))\n",
        "\n",
        "    # print model architecture\n",
        "    def show_model(self):\n",
        "        print('======================== Discriminator ========================')\n",
        "        print(self.D)\n",
        "        print('===========================================================\\n\\n')\n",
        "        print('========================== Generator ==========================')\n",
        "        print(self.G)\n",
        "        print('===========================================================\\n\\n')\n",
        "        # print('=========================== Encoder ===========================')\n",
        "        # print(self.E)\n",
        "        # print('===========================================================\\n\\n')\n",
        "\n",
        "    def set_train_phase(self):\n",
        "        self.D.train()\n",
        "        self.G.train()\n",
        "        #self.E.train()\n",
        "\n",
        "    # load pre_trained weight\n",
        "    def load_pretrained(self):\n",
        "        self.D.load_state_dict(torch.load(os.path.join(self.weight_dir, 'D.pkl')))\n",
        "        self.G.load_state_dict(torch.load(os.path.join(self.weight_dir, 'G.pkl')))\n",
        "        #self.E.load_state_dict(torch.load(os.path.join(self.weight_dir, 'E.pkl')))\n",
        "        \n",
        "        # log_file = open('log.txt', 'r')\n",
        "        # line = log_file.readline()\n",
        "        # self.start_epoch = int(line)\n",
        "\n",
        "    # save weight\n",
        "    def save_weight(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            d_name = 'D.pkl'\n",
        "            g_name = 'G.pkl'\n",
        "            #e_name = 'E.pkl'\n",
        "        else:\n",
        "            d_name = '{epochs}-{name}'.format(epochs=str(epoch), name='D.pkl')\n",
        "            g_name = '{epochs}-{name}'.format(epochs=str(epoch), name='G.pkl')\n",
        "            #e_name = '{epochs}-{name}'.format(epochs=str(epoch), name='E.pkl')\n",
        "            \n",
        "        torch.save(self.D.state_dict(), os.path.join(self.weight_dir, d_name))\n",
        "        torch.save(self.G.state_dict(), os.path.join(self.weight_dir, g_name))\n",
        "        #torch.save(self.E.state_dict(), os.path.join(self.weight_dir, e_name))\n",
        "\n",
        "    # set all optimizers' grad to zero\n",
        "    def all_zero_grad(self):\n",
        "        self.optim_D.zero_grad()\n",
        "        self.optim_G.zero_grad()\n",
        "        #self.optim_E.zero_grad()\n",
        "\n",
        "    # train G, D\n",
        "    def train(self):\n",
        "        if self.load_weight is True:\n",
        "            self.load_pretrained()\n",
        "\n",
        "        self.set_train_phase()\n",
        "        self.show_model()\n",
        "\n",
        "        # execute training\n",
        "        for epoch in range(self.start_epoch, self.num_epoch):\n",
        "            for batch_idx, dset in enumerate(self.dloader):                \n",
        "                # train D\n",
        "                # encoded latent vector\n",
        "                batch_size=self.batch_size\n",
        "                # mu, log_var = self.E(dset.type(self.dtype))\n",
        "                # std = torch.exp(log_var / 2)\n",
        "                #random_z = torch.randn(batch_size, 512).type(self.dtype)\n",
        "                #encoded_z = (random_z * std) + mu\n",
        "\n",
        "                # run mapping\n",
        "                #style_w = self.M(encoded_z)\n",
        "\n",
        "                # real image\n",
        "                real_img1 = dset.type(self.dtype)\n",
        "\n",
        "                # generate fake image\n",
        "                noise1 = torch.randn(batch_size,512).type(self.dtype)\n",
        "                fake_img1 = self.G(real_img1, noise1)                \n",
        "\n",
        "                # get score\n",
        "                real_score1 = self.D(real_img1)\n",
        "                fake_score1 = self.D(fake_img1.detach())\n",
        "\n",
        "                # define the loss function of the discriminator \n",
        "                D_loss = mse_loss(real_score1, 1) + mse_loss(fake_score1, 0)\n",
        "\n",
        "                # Update D\n",
        "                self.all_zero_grad()\n",
        "                D_loss.backward()\n",
        "                self.optim_D.step()\n",
        "\n",
        "                # Train G\n",
        "                # encoded latent vector\n",
        "                # real_img1 = dset.type(self.dtype)                \n",
        "                # mu1, log_var1 = self.E(real_img1)\n",
        "                # std = torch.exp(log_var1 / 2)\n",
        "                # random_z1 = torch.randn(batch_size, 512).type(self.dtype)\n",
        "                # encoded_z1 = (random_z1 * std) + mu\n",
        "\n",
        "                # run mapping\n",
        "                #style_w1 = self.M(encoded_z1)     \n",
        "\n",
        "                # real image\n",
        "                real_img2 = dset.type(self.dtype)           \n",
        "\n",
        "                # generate fake image\n",
        "                noise2 = torch.randn(batch_size,512).type(self.dtype)             \n",
        "                fake_img2 = self.G(real_img2, noise2)\n",
        "                \n",
        "                # get score\n",
        "                fake_score2 = self.D(fake_img2)\n",
        "\n",
        "                # fool the discriminator\n",
        "                G_GAN_loss = mse_loss(fake_score2, 1)\n",
        "\n",
        "                # Reconstruction of ground truth image (|G(noise, z) - real|)\n",
        "                recon_loss = L1_loss(fake_img1, real_img1)\n",
        "\n",
        "                # VGGLoss of ground truth image (|G(noise, z) - real|)    \n",
        "\n",
        "                vgg_loss = self.lambda_img*self.criterionVGG(fake_img2, real_img2)\n",
        "\n",
        "                # define EG_loss\n",
        "                G_loss = G_GAN_loss + vgg_loss + recon_loss\n",
        "                #EG_loss = G_GAN_loss + KL_div + recon_loss\n",
        "                self.all_zero_grad()\n",
        "                G_loss.backward()\n",
        "                #self.optim_E.step()\n",
        "                self.optim_G.step()\n",
        "\n",
        "                if batch_idx % 40 == 0:\n",
        "                    print('[Epoch : %d / Iters : %d] => D_loss : %f / G_GAN_loss : %f / vgg_loss : %f / recon_loss : %f'\\\n",
        "                            %(epoch, batch_idx, D_loss.data, G_GAN_loss.data, vgg_loss.data, recon_loss.data))\n",
        "\n",
        "                    # Save intermediate result image\n",
        "                    os.makedirs(self.result_dir,exist_ok=True)\n",
        "                    result_img = util.make_img(self.t_dloader, self.G)\n",
        "                    img_name = '{epoch}_{iters}.png'.format(epoch=epoch,iters=batch_idx) \n",
        "                    img_path = os.path.join(self.result_dir, img_name)\n",
        "\n",
        "                    torchvision.utils.save_image(result_img, img_path, nrow=self.test_img_num+1)\n",
        "\n",
        "            # Save intermediate weight\n",
        "            if os.path.exists(self.weight_dir) is False:\n",
        "                os.makedirs(self.weight_dir)\n",
        "\n",
        "            if epoch % 5 == 0: \n",
        "                self.save_weight(epoch=epoch)\n",
        "\n",
        "    def test(self, path, num):               \n",
        "        #weight_path = './output/gen_weights'\n",
        "        weight_path = path\n",
        "        Gen = self.G\n",
        "        Gen.load_state_dict(torch.load(os.path.join(weight_path, '435-G.pkl')))       \n",
        "        Gen.eval()\n",
        "        gen_num = num\n",
        "        n = 0\n",
        "        for n in range(gen_num):\n",
        "            # dloader = self.test_dloader\n",
        "            # # load real image\n",
        "            # dloader = iter(dloader)\n",
        "            # real_image = next(dloader)\n",
        "            # real_image = real_image.to(device)\n",
        "\n",
        "            fake_image = result_img = util.make_img(self.t_dloader, self.E, Gen)\n",
        "\n",
        "            # eta = torch.FloatTensor(1,1,1,1).uniform_(0,1)\n",
        "            # eta = eta.expand(1, real_image.size(1), real_image.size(2), real_image.size(3))\n",
        "            # eta = eta.to(device)\n",
        "            # gen_image = eta * real_image + ((1 - eta) * fake_image)\n",
        "            img_name = '{}.png'.format(n+1)\n",
        "            img_path = os.path.join('./output/gen_images', img_name)\n",
        "            torchvision.utils.save_image(fake_image, img_path, nrow=self.test_img_num+1)   \n",
        "            n += 1 "
      ],
      "metadata": {
        "id": "xdYZZrUh_JEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    gan = PRGan(batch_size=16,num_epoch=401,load_weight=False)\n",
        "    gan.train()\n",
        "    #gan.test(path='./output/gen_weights', num=3000)"
      ],
      "metadata": {
        "id": "Krl1k6Aq_kh7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}